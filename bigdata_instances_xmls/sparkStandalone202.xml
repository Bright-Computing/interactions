<sparkConfig>
  <archive>spark-2.0.2-bin-hadoop2.6.tgz</archive>
  <javahome>/usr/lib/jvm/jre/</javahome>
  <instance>
    <name>sparkStandalone202</name>
    <masters recovery="NONE">
      <hosts>node001</hosts>
      <port>7070</port>
      <webport>9080</webport>
      <historywebport>19080</historywebport>
      <localdir>/tmp/spark/spark202</localdir>
    </masters>
    <workers>
      <hosts>node002..node004</hosts>
      <port>7071</port>
      <webport>9081</webport>
      <numcores>0</numcores>
      <numinstances>1</numinstances>
      <workerdir>/tmp/spark/spark202</workerdir>
      <cleanupenabled>true</cleanupenabled>
      <cleanupinterval>1800</cleanupinterval>
      <cleanupappdatattl>604800</cleanupappdatattl>
    </workers>
  </instance>
</sparkConfig>
